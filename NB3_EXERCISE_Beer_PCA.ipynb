{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-ccdeaf65-9b95-4d9f-b84e-a1bdd65167a9",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.046226,
     "end_time": "2020-08-14T19:31:12.889193",
     "exception": false,
     "start_time": "2020-08-14T19:31:12.842967",
     "status": "completed"
    },
    "tags": [],
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Using-Principal-Component-Analysis-(PCA)-on-Deschutes-Fermentation-Data\" data-toc-modified-id=\"Using-Principal-Component-Analysis-(PCA)-on-Deschutes-Fermentation-Data-1\">Using Principal Component Analysis (PCA) on Deschutes Fermentation Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Goal\" data-toc-modified-id=\"The-Goal-1.1\">The Goal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Issues-to-consider\" data-toc-modified-id=\"Issues-to-consider-1.1.1\">Issues to consider</a></span></li></ul></li><li><span><a href=\"#This-Notebook\" data-toc-modified-id=\"This-Notebook-1.2\">This Notebook</a></span><ul class=\"toc-item\"><li><span><a href=\"#Part-1:-Define-System-Parameters\" data-toc-modified-id=\"Part-1:-Define-System-Parameters-1.2.1\">Part 1: Define System Parameters</a></span></li><li><span><a href=\"#Part-2:-Load-&amp;-Clean-Data\" data-toc-modified-id=\"Part-2:-Load-&amp;-Clean-Data-1.2.2\">Part 2: Load &amp; Clean Data</a></span></li><li><span><a href=\"#Part-3:-Define-Utility-Functions\" data-toc-modified-id=\"Part-3:-Define-Utility-Functions-1.2.3\">Part 3: Define Utility Functions</a></span></li><li><span><a href=\"#Part-4:-Process-and-Summarize-Data\" data-toc-modified-id=\"Part-4:-Process-and-Summarize-Data-1.2.4\">Part 4: Process and Summarize Data</a></span></li><li><span><a href=\"#Part-5:-Apply-PCA-to-FeatureDF\" data-toc-modified-id=\"Part-5:-Apply-PCA-to-FeatureDF-1.2.5\">Part 5: Apply PCA to <code>FeatureDF</code></a></span></li><li><span><a href=\"#Part-6-(BONUS):-Apply-clustering-to-Principal-Components:\" data-toc-modified-id=\"Part-6-(BONUS):-Apply-clustering-to-Principal-Components:-1.2.6\">Part 6 (BONUS): Apply clustering to Principal Components:</a></span></li></ul></li><li><span><a href=\"#Your-Task\" data-toc-modified-id=\"Your-Task-1.3\">Your Task</a></span></li><li><span><a href=\"#Part-1.-Define-System-Parameters\" data-toc-modified-id=\"Part-1.-Define-System-Parameters-1.4\">Part 1. Define System Parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#1a.-Define-relevant-main-variables\" data-toc-modified-id=\"1a.-Define-relevant-main-variables-1.4.1\">1a. Define relevant main variables</a></span></li><li><span><a href=\"#1b.-Define-auxiliary-variables\" data-toc-modified-id=\"1b.-Define-auxiliary-variables-1.4.2\">1b. Define auxiliary variables</a></span></li><li><span><a href=\"#1c.-PCA-coordinates-selection\" data-toc-modified-id=\"1c.-PCA-coordinates-selection-1.4.3\">1c. PCA coordinates selection</a></span></li></ul></li><li><span><a href=\"#Part-2.-Load-&amp;-Clean-Data\" data-toc-modified-id=\"Part-2.-Load-&amp;-Clean-Data-1.5\">Part 2. Load &amp; Clean Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#2a.-Initialize-Hub-client\" data-toc-modified-id=\"2a.-Initialize-Hub-client-1.5.1\">2a. Initialize Hub client</a></span></li><li><span><a href=\"#2b.-Download-data-from-OCS-with-Data-Views\" data-toc-modified-id=\"2b.-Download-data-from-OCS-with-Data-Views-1.5.2\">2b. Download data from OCS with Data Views</a></span></li><li><span><a href=\"#Find-predefined-multi-asset-Data-View-for-Fermenters-31-36-and-PCA\" data-toc-modified-id=\"Find-predefined-multi-asset-Data-View-for-Fermenters-31-36-and-PCA-1.5.3\">Find predefined multi-asset Data View for Fermenters 31-36 and PCA</a></span></li><li><span><a href=\"#Data-View-Structure\" data-toc-modified-id=\"Data-View-Structure-1.5.4\">Data View Structure</a></span></li><li><span><a href=\"#Get-Interpolated-Data-from-Data-Views\" data-toc-modified-id=\"Get-Interpolated-Data-from-Data-Views-1.5.5\">Get Interpolated Data from Data Views</a></span></li><li><span><a href=\"#2c.-Clean-all_brands_df\" data-toc-modified-id=\"2c.-Clean-all_brands_df-1.5.6\">2c. Clean <code>all_brands_df</code></a></span></li></ul></li><li><span><a href=\"#Part-3.-Define-Utility-Functions\" data-toc-modified-id=\"Part-3.-Define-Utility-Functions-1.6\">Part 3. Define Utility Functions</a></span></li><li><span><a href=\"#Part-4.-Process-and-Summarize-Data\" data-toc-modified-id=\"Part-4.-Process-and-Summarize-Data-1.7\">Part 4. Process and Summarize Data</a></span></li><li><span><a href=\"#Part-5.-Apply-PCA-to-FeatureDF\" data-toc-modified-id=\"Part-5.-Apply-PCA-to-FeatureDF-1.8\">Part 5. Apply PCA to <code>FeatureDF</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#5a.-Define-and-scale-the-feature-space\" data-toc-modified-id=\"5a.-Define-and-scale-the-feature-space-1.8.1\">5a. Define and scale the feature space</a></span></li><li><span><a href=\"#5b.-Apply-PCA-to-the-feature-space\" data-toc-modified-id=\"5b.-Apply-PCA-to-the-feature-space-1.8.2\">5b. Apply PCA to the feature space</a></span></li><li><span><a href=\"#5c.-Find-number-of-principal-components-sufficent-to-explain-data\" data-toc-modified-id=\"5c.-Find-number-of-principal-components-sufficent-to-explain-data-1.8.3\">5c. Find number of principal components sufficent to explain data</a></span></li><li><span><a href=\"#5d.-Visualize-Deschutes-data-using-the-principal-components\" data-toc-modified-id=\"5d.-Visualize-Deschutes-data-using-the-principal-components-1.8.4\">5d. Visualize Deschutes data using the principal components</a></span></li><li><span><a href=\"#5e.-What's-in-an-outlier?\" data-toc-modified-id=\"5e.-What's-in-an-outlier?-1.8.5\">5e. What's in an outlier?</a></span></li></ul></li><li><span><a href=\"#Part-6.-Apply-clustering-to-Principal-Components-(BONUS)\" data-toc-modified-id=\"Part-6.-Apply-clustering-to-Principal-Components-(BONUS)-1.9\">Part 6. Apply clustering to Principal Components (BONUS)</a></span><ul class=\"toc-item\"><li><span><a href=\"#6a.-Apply-k-means-clustering-on-the-principal-components\" data-toc-modified-id=\"6a.-Apply-k-means-clustering-on-the-principal-components-1.9.1\">6a. Apply k-means clustering on the principal components</a></span></li><li><span><a href=\"#6b.-Plot-principal-components-and-color-by-kmeans-cluster\" data-toc-modified-id=\"6b.-Plot-principal-components-and-color-by-kmeans-cluster-1.9.2\">6b. Plot principal components and color by kmeans cluster</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-a55920f4-5eff-4d80-a632-9236a2952d6a",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.027902,
     "end_time": "2020-08-14T19:31:12.949630",
     "exception": false,
     "start_time": "2020-08-14T19:31:12.921728",
     "status": "completed"
    },
    "tags": [],
    "toc-hr-collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00002-e3ff8f0c-17f3-4b3d-add9-aa70da910673",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:13.003344Z",
     "iopub.status.busy": "2020-08-14T19:31:13.002420Z",
     "iopub.status.idle": "2020-08-14T19:31:20.123131Z",
     "shell.execute_reply": "2020-08-14T19:31:20.123945Z"
    },
    "execution_millis": 1546,
    "execution_start": 1642208613582,
    "output_cleared": false,
    "papermill": {
     "duration": 7.149791,
     "end_time": "2020-08-14T19:31:20.124149",
     "exception": false,
     "start_time": "2020-08-14T19:31:12.974358",
     "status": "completed"
    },
    "source_hash": "b09a7dc1",
    "tags": [],
    "toc-hr-collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-1a6ccd60-716e-4db3-97c8-25dadd9eca15",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.029669,
     "end_time": "2020-08-14T19:31:20.188787",
     "exception": false,
     "start_time": "2020-08-14T19:31:20.159118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# Using Principal Component Analysis (PCA) on Deschutes Fermentation Data\n",
    "---\n",
    "It is often useful to be able to quickly determine whether and which of the production batches are out-of-spec. The ability to determine the origin or the cause of a process failure or a bad batch is valuable to industry.\n",
    "\n",
    "In this notebook, we will use Principal Component Analysis (PCA) to determine which batches are out-of-spec without having to analyze the time series data for every attribute of erach beer batch, of which there are dozens. We will then use the properties of PCA to identify what may have caused a batch to be out-of-spec.\n",
    "\n",
    "First, make sure the latest version library for OCS is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00004-7576354b-f4d1-4c86-b83d-e6ef2d5a41da",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:20.257320Z",
     "iopub.status.busy": "2020-08-14T19:31:20.256569Z",
     "iopub.status.idle": "2020-08-14T19:31:23.443162Z",
     "shell.execute_reply": "2020-08-14T19:31:23.442351Z"
    },
    "execution_millis": 20534,
    "execution_start": 1642208615173,
    "output_cleared": false,
    "papermill": {
     "duration": 3.222484,
     "end_time": "2020-08-14T19:31:23.443417",
     "exception": false,
     "start_time": "2020-08-14T19:31:20.220933",
     "status": "completed"
    },
    "source_hash": "79c22b68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import ocs_academic_hub\n",
    "except ModuleNotFoundError:\n",
    "    !pip install ocs-academic-hub==0.99.42\n",
    "    import ocs_academic_hub\n",
    "\n",
    "!pip install plotly_express==0.4.1 sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-4998af82-3302-44f8-a17b-b828de8e37a3",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.065025,
     "end_time": "2020-08-14T19:31:23.560791",
     "exception": false,
     "start_time": "2020-08-14T19:31:23.495766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00006-5d50bdae-3beb-4587-b2c8-e63535c46b1d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:23.688693Z",
     "iopub.status.busy": "2020-08-14T19:31:23.687573Z",
     "iopub.status.idle": "2020-08-14T19:31:24.137545Z",
     "shell.execute_reply": "2020-08-14T19:31:24.138096Z"
    },
    "execution_millis": 2275,
    "execution_start": 1642208635718,
    "output_cleared": false,
    "papermill": {
     "duration": 0.51988,
     "end_time": "2020-08-14T19:31:24.138291",
     "exception": false,
     "start_time": "2020-08-14T19:31:23.618411",
     "status": "completed"
    },
    "source_hash": "3b6fb1ec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Academic Hub module \n",
    "from ocs_academic_hub.datahub import hub_login\n",
    "\n",
    "# For OCS configuration and data manipulation\n",
    "import configparser\n",
    "from dateutil import parser\n",
    "import datetime as dt\n",
    "\n",
    "# analysis packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# packages for PCA. sklearn is standard Python library for machine learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# packages for plotting\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "print(\"--- import completed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-0898e64c-a613-412d-869c-b66ba251c7c5",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.033845,
     "end_time": "2020-08-14T19:31:24.209939",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.176094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## The Goal\n",
    "Use Principal Component Analysis (PCA) to identify the bad beer batches in 300 days worth of process data involving 4 beer brands (Realtime Hops, Trois Lacs, Grey Horse and LIT), brewed across 6 fermentor vessels (31-36). \n",
    "\n",
    "Also, use the properties of Principal Components (PCs or \"scores\") to identify what features are most responsible for contributing to the out-of-spec qualities of outlier beer batches.\n",
    "\n",
    "### Issues to consider\n",
    "* Real process data is dirty (sensors can fail)\n",
    "* The stages may have been mislabeled (e.g. entries in \"Cooling\" phase may have been mislabled as being in \"Diacetyl Rest\")\n",
    "* Different cooling temperatures for each beer batch, and even for each zone in a fermentor vessel for a given beer batch\n",
    "* There can be various volumes of beer in the fermentors\n",
    "* Data can have abrupt, aphysical jumps in temperature\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-743f82b6-5384-4804-9000-c92ab4e3a7d6",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.028773,
     "end_time": "2020-08-14T19:31:24.272461",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.243688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## This Notebook\n",
    "\n",
    "### Part 1: Define System Parameters\n",
    "Specify parameters of interest like brands, fermentors, time period to analyze, time granularity, attributes.\n",
    "\n",
    "### Part 2: Load & Clean Data\n",
    "use OSIsoft Cloud Services (OCS) to obtain process data from Deschutes Brewery.\n",
    "\n",
    "### Part 3: Define Utility Functions\n",
    "Create utility functions for calculating the time elapsed per batch, identifying fermentation stages without relying on the \"Status\" labels, removing the bad batches, and summarizing the data.\n",
    "\n",
    "### Part 4: Process and Summarize Data\n",
    "Execute the functions created in Part 3 for each brand in each fermentor vessel. Collect the summary of the data into the dataframe `FeatureDF`.\n",
    "\n",
    "### Part 5: Apply PCA to `FeatureDF`\n",
    "`FeatureDF` is a high-dimensional dataset that is not easily human-processable. Use Principal Components Analysis (PCA) to obtain new components composed of linear combinations of the most \"relevant\" input features in `FeatureDF`( [5a](#section_5a)-[5c](#section_5c)); use those components to graphically visualize `FeatureDF` and identify the bad batches [5d](#section_5d); then identify the input features which contributed to the out-of-spec characteristics of the outlier batches ([5e](#section_5e)).\n",
    "\n",
    "### Part 6 (BONUS): Apply clustering to Principal Components:\n",
    "Use the k-means clustering algorithm to classify data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-9208683f-a49a-4111-b0b3-8151ff4caef7",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.044334,
     "end_time": "2020-08-14T19:31:24.360563",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.316229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Your Task\n",
    "Some cells have missing pieces of code and are marked with `TODO` items in comments. Complete all the missing code to obtain a working notebook. \n",
    "\n",
    "If the notebook runs as inteded, using the default seetings in [Part 1a](#section_1a), one should obtain this plot in [Part 5e](#section_5e):\n",
    "\n",
    "![](https://academichub.blob.core.windows.net/images/nb3_pca_scatterplot_new_v6.png)\n",
    "\n",
    "(NOTE: `TODO` items can be found in [Part 3](#section_3) only, but this exercise will be easier if you go through it in sequential order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-270ba93f-859a-402e-89a5-032e362fd7ea",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.027371,
     "end_time": "2020-08-14T19:31:24.418979",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.391608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Part 1. Define System Parameters\n",
    "---\n",
    "<a id=’section_1’></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-40f99f68-e881-4f70-b2e9-37dee1faf3b8",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.03041,
     "end_time": "2020-08-14T19:31:24.476994",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.446584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1a. Define relevant main variables\n",
    "<a id=’section_1a’></a>\n",
    "\n",
    "We want 3 years of brewing data from 6 fermentor vessels (31-36), beginning on January 11, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00012-55359d81-8ce2-4d6e-92b3-c17b3d85b1d5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:24.549717Z",
     "iopub.status.busy": "2020-08-14T19:31:24.548854Z",
     "iopub.status.idle": "2020-08-14T19:31:24.551164Z",
     "shell.execute_reply": "2020-08-14T19:31:24.551712Z"
    },
    "execution_millis": 15,
    "execution_start": 1642208638007,
    "output_cleared": false,
    "papermill": {
     "duration": 0.044403,
     "end_time": "2020-08-14T19:31:24.551877",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.507474",
     "status": "completed"
    },
    "source_hash": "eab244dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fermenters to analyze as a list of integers\n",
    "FERMENTORS_OF_INTEREST = [str(i) for i in range(31, 37)]\n",
    "\n",
    "# brands of interest (brand `None` indicates that no beer in actually processing)\n",
    "BRANDS_OF_INTEREST = [\"Realtime Hops\", \"Trois Lacs\", \"Grey Horse\", \"LIT\"]\n",
    "\n",
    "\n",
    "# relevant days over which to analyze fermentors - 3 years\n",
    "TRAINING_DAYS = 3 * 365\n",
    "\n",
    "# time period in which to analyze fermentation data\n",
    "START_INDEX = \"2017-01-11T00:00\"\n",
    "END_INDEX = (parser.parse(START_INDEX) + dt.timedelta(days=TRAINING_DAYS)).isoformat()\n",
    "\n",
    "# define time grandularity for data. in this case, get events at 15 minute intervals\n",
    "INDEX_INTERVAL = \"00:15:00\"\n",
    "print(\"--- main variables defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-f83b9dcb-288c-4faa-86ee-1e3fdef7acbd",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.029986,
     "end_time": "2020-08-14T19:31:24.610079",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.580093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1b. Define auxiliary variables\n",
    "<a id=’section_1b’></a>\n",
    "Make code more readable by avoiding to type long strings repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00014-3ee0f8a7-c358-4600-bf16-fec77d3f834c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:24.683883Z",
     "iopub.status.busy": "2020-08-14T19:31:24.682174Z",
     "iopub.status.idle": "2020-08-14T19:31:24.689351Z",
     "shell.execute_reply": "2020-08-14T19:31:24.690046Z"
    },
    "execution_millis": 2,
    "execution_start": 1642208638065,
    "output_cleared": false,
    "papermill": {
     "duration": 0.050421,
     "end_time": "2020-08-14T19:31:24.690343",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.639922",
     "status": "completed"
    },
    "source_hash": "cb000755",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TIC PV column names (temperatures)\n",
    "TIC_PV_COLUMNS = [\"Bottom TIC PV\", \"Middle TIC PV\", \"Top TIC PV\"]\n",
    "\n",
    "# TIC OUT column names (cooling intensities)\n",
    "TIC_OUT_COLUMNS = [\"Bottom TIC OUT\", \"Middle TIC OUT\", \"Top TIC OUT\"]\n",
    "\n",
    "# list of relevant attributes. these attributes should not have any bad inputs\n",
    "ATTRIBUTES_OF_INTEREST = (\n",
    "    [\"Brand\", \"Status\", \"Volume\", \"ADF\"] + TIC_PV_COLUMNS + TIC_OUT_COLUMNS\n",
    ")\n",
    "\n",
    "\n",
    "# define stages involved in overall fermentation process\n",
    "ALL_BREWING_STAGES = [\n",
    "    \"Filling\",\n",
    "    \"Fermentation\",\n",
    "    \"Free Rise\",\n",
    "    \"Diacetyl Rest\",\n",
    "    \"Cooling\",\n",
    "    \"Maturation\",\n",
    "    \"Ready to Transfer\",\n",
    "    \"Emptying\",\n",
    "    \"Clean\",\n",
    "    \"CIP\",\n",
    "]\n",
    "\n",
    "# define stages which can actually affect beer quality\n",
    "IMPORTANT_BREWING_STAGES = ALL_BREWING_STAGES[\n",
    "    1:6\n",
    "]  # Fermentation->Free Rise->Diacetyl Rest->Cooling\n",
    "\n",
    "\n",
    "# Stages to consider as part of the fermentation stage\n",
    "FERMENTATION_STAGES = [\"Fermentation\"]  #  \"Free Rise\", \"Diacetyl Rest\"]\n",
    "\n",
    "# assign an integer value for each brand\n",
    "brand_dictionary = {brand: (i + 1) for i, brand in enumerate(BRANDS_OF_INTEREST)}\n",
    "print(\"--- auxiliary variables defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-eea0b677-2d1f-4dd5-83b8-53beea6b7f82",
    "deepnote_cell_type": "markdown",
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:24.683883Z",
     "iopub.status.busy": "2020-08-14T19:31:24.682174Z",
     "iopub.status.idle": "2020-08-14T19:31:24.689351Z",
     "shell.execute_reply": "2020-08-14T19:31:24.690046Z"
    },
    "papermill": {
     "duration": 0.050421,
     "end_time": "2020-08-14T19:31:24.690343",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.639922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1c. PCA coordinates selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00016-f29d99c1-e952-4ff4-bcea-745e1b44e6c3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:24.683883Z",
     "iopub.status.busy": "2020-08-14T19:31:24.682174Z",
     "iopub.status.idle": "2020-08-14T19:31:24.689351Z",
     "shell.execute_reply": "2020-08-14T19:31:24.690046Z"
    },
    "execution_millis": 5,
    "execution_start": 1642208638066,
    "output_cleared": false,
    "papermill": {
     "duration": 0.050421,
     "end_time": "2020-08-14T19:31:24.690343",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.639922",
     "status": "completed"
    },
    "source_hash": "bc99ac76",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PCA COORDINATES SELECTION\n",
    "\n",
    "# For temperature sensors with multiple positions, the list\n",
    "# position_active selects which ones are selected for PCA.\n",
    "#\n",
    "# NOTE: at least one position should be True otherwise no sensor\n",
    "# will be used in PCA even if a 1 is present for the first item in\n",
    "# PCList below\n",
    "#\n",
    "#                  TOP,   MIDDLE, BOTTOM\n",
    "position_active = [False, False, True]\n",
    "\n",
    "# List of the names of coordinates to be used for PCA.\n",
    "# The first item of each indicates if the coordinates is used for PCA (1 for active).\n",
    "# For sensors with position, see position_active above.\n",
    "#\n",
    "PClist = [\n",
    "    (1, [\"Brand\"]),  # brand identifier - FIRST COLUMN SHOULD ALWAYS BE 1\n",
    "    (1, [\"Batch\"]),  # batch identifier - FIRST COLUMN SHOULD ALWAYS BE 1\n",
    "    (1, [\"FERM_ADF\"]),  # variance of ADF during primary fermentation\n",
    "    (0, [\"COOL_ADF\"]),  # average adf after primary fermentation\n",
    "    (0, [\"Volume\"]),  # average volume after primary fermentation\n",
    "    (1, [\"FERM_Duration\"]),  # total time PRIMARY FERMENTATION lasted\n",
    "    # average value for cooling intensity during PRIMARY FERMENTATION at different zones\n",
    "    (1, [\"FERM_avg_coolint_top\", \"FERM_avg_coolint_middle\", \"FERM_avg_coolint_bottom\"]),\n",
    "    # average value for temperature during PRIMARY FERMENTATION at different zones\n",
    "    (1, [\"FERM_avg_temp_top\", \"FERM_avg_temp_middle\", \"FERM_avg_temp_bottom\"]),\n",
    "    # maximum value for temperature during PRIMARY FERMENTATION at different zones\n",
    "    (1, [\"FERM_max_temp_top\", \"FERM_max_temp_middle\", \"FERM_max_temp_bottom\"]),\n",
    "    # minimum value for temperature during PRIMARY FERMENTATION at different zones\n",
    "    (1, [\"FERM_min_temp_top\", \"FERM_min_temp_middle\", \"FERM_min_temp_bottom\"]),\n",
    "    # variance of the temperature during PRIMARY FERMENTATION at different zones\n",
    "    (1, [\"FERM_var_temp_top\", \"FERM_var_temp_middle\", \"FERM_var_temp_bottom\"]),\n",
    "    # average of the variance between zones per event during PRIMARY FERMENTATION\n",
    "    (1, [\"FERM_var_between_zones\"]),\n",
    "    (0, [\"COOL_Duration\"]),  # total time COOLING lasted\n",
    "    # average value for cooling intensity during COOLING at different zones\n",
    "    (0, [\"COOL_avg_coolint_top\", \"COOL_avg_coolint_middle\", \"COOL_avg_coolint_bottom\"]),\n",
    "    # average value for temperature during COOLING at different zones\n",
    "    (0, [\"COOL_avg_temp_top\", \"COOL_avg_temp_middle\", \"COOL_avg_temp_bottom\"]),\n",
    "    # maximum value for temperature during COOLING at different zones\n",
    "    (0, [\"COOL_max_temp_top\", \"COOL_max_temp_middle\", \"COOL_max_temp_bottom\"]),\n",
    "    # minimum value for temperature during COOLING at different zones\n",
    "    (0, [\"COOL_min_temp_top\", \"COOL_min_temp_middle\", \"COOL_min_temp_bottom\"]),\n",
    "    # initial value for temperature during COOLING at different zones\n",
    "    (0, [\"COOL_init_temp_top\", \"COOL_init_temp_middle\", \"COOL_init_temp_bottom\"]),\n",
    "    # variance of the temperature during PRIMARY FERMENTATION at different zones\n",
    "    (0, [\"COOL_var_temp_top\", \"COOL_var_temp_middle\", \"COOL_var_temp_bottom\"]),\n",
    "    # average of the variance between zones per event during COOLING\n",
    "    (0, [\"COOL_var_between_zones\"]),\n",
    "]\n",
    "\n",
    "\n",
    "# ==================== END PCA COORDINATES SELECTION ================\n",
    "print(\"--- PCA coordinates selection done ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-64f2b275-49f3-44c7-bcf2-c3fc813296bb",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.06186,
     "end_time": "2020-08-14T19:31:24.815436",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.753576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Part 2. Load & Clean Data\n",
    "---\n",
    "<a id=’section_2’></a>\n",
    "The Deschutes Brewery data needs to be retrieved from OSIsoft Cloud Services (OCS). \n",
    "\n",
    "We need to retrieve data for the `FERMENTORS_OF_INTEREST` from time period `START_INDEX` to `END_INDEX` at a resolution of `INDEX_INTERVAL` between each event. \n",
    "\n",
    "The data retrieved from OCS is loaded into a dataframe, which is then filtered to ensure it will not contain a missing value for any value in the `ATTRIBUTES_OF_INTEREST` before it is processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-da21ee99-548a-44bd-848f-7575307a1e94",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.027527,
     "end_time": "2020-08-14T19:31:24.880304",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.852777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2a. Initialize Hub client\n",
    "<a id=’section_2a’></a>\n",
    "\n",
    "**Execute the cell below and follow the indicated steps to log in (an AVEVA banner would show up)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00019-e2cea5f8-ea7a-4408-8a6c-cffe571dc9cf",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     2
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:25.006068Z",
     "iopub.status.busy": "2020-08-14T19:31:25.005118Z",
     "iopub.status.idle": "2020-08-14T19:31:25.114701Z",
     "shell.execute_reply": "2020-08-14T19:31:25.115924Z"
    },
    "execution_millis": 2066,
    "execution_start": 1642208638083,
    "output_cleared": false,
    "papermill": {
     "duration": 0.185083,
     "end_time": "2020-08-14T19:31:25.116214",
     "exception": false,
     "start_time": "2020-08-14T19:31:24.931131",
     "status": "completed"
    },
    "source_hash": "4fb18ac1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "widget, hub_client = hub_login()\n",
    "widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "2b07d178-2c94-434c-bd47-8e691a72738d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1642208640237,
    "source_hash": "3af7670e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = hub_client.current_dataset()\n",
    "namespace_id = hub_client.namespace_of(dataset)\n",
    "print(f\"Current dataset is {dataset} in namespace_id: {namespace_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-6a42fe73-e5a7-483a-bf90-547b1bfdda54",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.064351,
     "end_time": "2020-08-14T19:31:25.246811",
     "exception": false,
     "start_time": "2020-08-14T19:31:25.182460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2b. Download data from OCS with Data Views\n",
    "<a id=’section_2b’></a>\n",
    "\n",
    "**Development tip (WARNING: executing dataview takes up to 3 minutes)** \n",
    "\n",
    "Development of a notebook involves running code over and over, so you'll want to avoid long running steps when possible. This is why you can run the cell below once, with the resulting dataframe saved in variable `all_brands_df`. If you don't change any of its input parameters, `all_brands_df` is still valid and can be reused. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-e6cf7c2f-925b-4cdc-97cf-ec8f7f35e39c",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.064135,
     "end_time": "2020-08-14T19:31:25.372821",
     "exception": false,
     "start_time": "2020-08-14T19:31:25.308686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Find predefined multi-asset Data View for Fermenters 31-36 and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00022-4edc4176-273b-46a3-bfff-9cf4053166bb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:25.499000Z",
     "iopub.status.busy": "2020-08-14T19:31:25.497987Z",
     "iopub.status.idle": "2020-08-14T19:31:25.503349Z",
     "shell.execute_reply": "2020-08-14T19:31:25.504227Z"
    },
    "execution_millis": 3371020670,
    "execution_start": 1642208640238,
    "output_cleared": false,
    "papermill": {
     "duration": 0.076267,
     "end_time": "2020-08-14T19:31:25.504448",
     "exception": false,
     "start_time": "2020-08-14T19:31:25.428181",
     "status": "completed"
    },
    "source_hash": "424f58b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dv_id = hub_client.asset_dataviews(filter=\"pca\", asset=\"FV31\", multiple_asset=True)[0]\n",
    "print(dv_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-8d08a0dd-0f0b-41c7-a867-3f6da39c8e64",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.065768,
     "end_time": "2020-08-14T19:31:25.650352",
     "exception": false,
     "start_time": "2020-08-14T19:31:25.584584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data View Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00024-49cf544c-c4fb-4a9d-b293-b0f61b5f767d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:25.775323Z",
     "iopub.status.busy": "2020-08-14T19:31:25.774462Z",
     "iopub.status.idle": "2020-08-14T19:31:26.335820Z",
     "shell.execute_reply": "2020-08-14T19:31:26.335186Z"
    },
    "execution_millis": 960,
    "execution_start": 1642208640238,
    "output_cleared": false,
    "papermill": {
     "duration": 0.6251,
     "end_time": "2020-08-14T19:31:26.335988",
     "exception": false,
     "start_time": "2020-08-14T19:31:25.710888",
     "status": "completed"
    },
    "source_hash": "958753ab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(hub_client.dataview_definition(namespace_id, dv_id).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-acafe206-36fd-4ff5-a6f2-aceea80cf759",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.034906,
     "end_time": "2020-08-14T19:31:26.409890",
     "exception": false,
     "start_time": "2020-08-14T19:31:26.374984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get Interpolated Data from Data Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00026-9535762b-48d8-454b-9966-c100f7a80067",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     177
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:31:26.488081Z",
     "iopub.status.busy": "2020-08-14T19:31:26.486801Z",
     "iopub.status.idle": "2020-08-14T19:32:49.442303Z",
     "shell.execute_reply": "2020-08-14T19:32:49.442901Z"
    },
    "execution_millis": 162560,
    "execution_start": 1642208641203,
    "output_cleared": false,
    "papermill": {
     "duration": 82.999296,
     "end_time": "2020-08-14T19:32:49.443129",
     "exception": false,
     "start_time": "2020-08-14T19:31:26.443833",
     "status": "completed"
    },
    "source_hash": "20edc48d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve data from OCS\n",
    "# TODO: complete call to multiple data views\n",
    "# =========== STUDENT BEGIN ==========\n",
    "\n",
    "all_brands_df = @@@ Your code here @@@.@@@ Your code here @@@_pd(...,...,...,...,INDEX_INTERVAL)\n",
    "\n",
    "# =========== STUDENT END ==========\n",
    "\n",
    "# preview `all_brands_df`\n",
    "all_brands_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00027-948af9bb-8feb-4948-a061-b3e804bc3d53",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:32:49.565796Z",
     "iopub.status.busy": "2020-08-14T19:32:49.565062Z",
     "iopub.status.idle": "2020-08-14T19:32:49.671817Z",
     "shell.execute_reply": "2020-08-14T19:32:49.671264Z"
    },
    "execution_millis": 234,
    "execution_start": 1642208803773,
    "output_cleared": false,
    "papermill": {
     "duration": 0.171822,
     "end_time": "2020-08-14T19:32:49.671961",
     "exception": false,
     "start_time": "2020-08-14T19:32:49.500139",
     "status": "completed"
    },
    "source_hash": "1d8d3f89",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe summary\n",
    "all_brands_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-62c21a73-0c1c-49b6-9e5f-cf1398842607",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.059398,
     "end_time": "2020-08-14T19:32:49.791393",
     "exception": false,
     "start_time": "2020-08-14T19:32:49.731995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2c. Clean `all_brands_df`\n",
    "<a id=’section_2c’></a>\n",
    "Drops all entries which have missing value in any columns in listed in `ATTRIBUTES_OF_INTEREST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00029-9d29dfec-ba5e-425b-9271-a10064965462",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:32:49.946720Z",
     "iopub.status.busy": "2020-08-14T19:32:49.945876Z",
     "iopub.status.idle": "2020-08-14T19:32:50.261329Z",
     "shell.execute_reply": "2020-08-14T19:32:50.260826Z"
    },
    "execution_millis": 615,
    "execution_start": 1642208804019,
    "output_cleared": false,
    "papermill": {
     "duration": 0.394659,
     "end_time": "2020-08-14T19:32:50.261446",
     "exception": false,
     "start_time": "2020-08-14T19:32:49.866787",
     "status": "completed"
    },
    "source_hash": "2920aebe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop rows with NaNs in attributes of interest\n",
    "all_brands_df = all_brands_df.dropna(subset=ATTRIBUTES_OF_INTEREST)\n",
    "\n",
    "all_brands_df[\"Asset_Id\"] = all_brands_df[\"Asset_Id\"].apply(lambda vessel: vessel[-2:])\n",
    "\n",
    "# all_brands_df.describe(include='all')\n",
    "all_brands_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00030-cb3e06e8-f3c3-416b-88e3-992b546525eb",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     366.6875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:32:50.399748Z",
     "iopub.status.busy": "2020-08-14T19:32:50.398883Z",
     "iopub.status.idle": "2020-08-14T19:32:50.487313Z",
     "shell.execute_reply": "2020-08-14T19:32:50.487733Z"
    },
    "execution_millis": 338,
    "execution_start": 1642208804442,
    "output_cleared": false,
    "papermill": {
     "duration": 0.171538,
     "end_time": "2020-08-14T19:32:50.488065",
     "exception": false,
     "start_time": "2020-08-14T19:32:50.316527",
     "status": "completed"
    },
    "source_hash": "25b08637",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA will be performed on the 4 brands with the most fermentations\n",
    "# Note 1: those are upper bounds since a fermentation can be discarded if incomplete or with bad data\n",
    "all_brands_df.groupby(by=[\"Fermentation Start Time\"]).first()[\"Brand\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-afcc3dbb-26ec-4dbe-ab44-94179f0a43e4",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.079127,
     "end_time": "2020-08-14T19:32:50.624841",
     "exception": false,
     "start_time": "2020-08-14T19:32:50.545714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Part 3. Define Utility Functions\n",
    "---\n",
    "<a id=’section_3’></a>\n",
    "Given a dataframe containing the fermentation data for one brand, first find all the different fermentation batches; then for each batch, we need to identify which stage each event belongs to.\n",
    "\n",
    "However, the \"Status\" labels are unreliable, so the stages have to be indetified through other means. Since it can be difficult to identify the transition between different stages, we consider only two rough categories of stages: (1) Pre (not) cooling and (2) Cooling.\n",
    "\n",
    "The  general \"Precooling\" stage will contain the literal \"Fermentation\", \"Free Rise\", \"Diacetyl Rest\" stages, while the general \"Cooling\" stage will contain the literal \"Cooling\" and \"Maturation\" stages. To distinguish \"Precooling\" and \"Cooling\" rows, a new boolean column \"Cooling_Stage\" contains a False or True value respectively.   \n",
    "\n",
    "We then want to create a summary of each batch, such that we can capture the general property of each batch. The summary for each batch will be collected in the dataframe `FeatureDF`.\n",
    "\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "|`fermentation_times`| Identify when fermentation begins; offset timestamps to begin on fermentation starts; add unique label to each fermentation batch|\n",
    "|`remove_batches_without_phase` | Certain stages are critical to flavor profile of beer; batches without these stages are just bad|\n",
    "|`organize_by_cooling`| finds when cooling starts and then relabels statuses as being either in 'Precooling' or 'Cooling' stages. Necessary because entries may have been mislabelled.|\n",
    "|`summarize_by_batch`| summarizes the time evolution of 10 attributes into 41 scalars. the summary is stored in a dataframe `ProcessedData`|\n",
    "\n",
    "The utility functions can all be found in the cell below (don't forget to execute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00032-0f05425e-8fd6-4450-bf71-7dc1a2593cfa",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:32:50.777609Z",
     "iopub.status.busy": "2020-08-14T19:32:50.765955Z",
     "iopub.status.idle": "2020-08-14T19:32:50.779881Z",
     "shell.execute_reply": "2020-08-14T19:32:50.779485Z"
    },
    "execution_millis": 118,
    "execution_start": 1642208804664,
    "output_cleared": false,
    "papermill": {
     "duration": 0.099512,
     "end_time": "2020-08-14T19:32:50.780030",
     "exception": false,
     "start_time": "2020-08-14T19:32:50.680518",
     "status": "completed"
    },
    "source_hash": "234f7dfa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoCoolingStagesFound(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def fermentation_times(brand_df, fermentation_starts, shift=0):\n",
    "    \"\"\"\n",
    "    DESCRIPTION: Identify when fermentation begins and &\n",
    "        offsets timestamps to start when fermentation begins.\n",
    "        Also adds a label to each new fermentation batch\n",
    "    RETURNS: the input dataframe with offset timestamps, labels for each batch\n",
    "    \"\"\"\n",
    "\n",
    "    # create new df columns \"tsf\" and \"batch\". NOTE: \"tsf\" --> \"time since fermentation\"\n",
    "    # TODO: initialize \"tsf\" with 100000 and \"batch\" with -1\n",
    "    # =========== STUDENT BEGIN ==========\n",
    "    brand_df = brand_df.assign(**{\"tsf\": 100000, @@@ Your code here @@@})\n",
    "    # =========== STUDENT END ==========\n",
    "\n",
    "    # reset index for fermentation starts, so that position index for .iterrows() is correct\n",
    "    fermentation_starts.reset_index(inplace=True)\n",
    "\n",
    "    # calculate the time elapsed for each fermentation step belonging to a new fermentation stage\n",
    "    for count, ferm_begin in fermentation_starts.iterrows():\n",
    "\n",
    "        # get the timestamp for each start of fermentation\n",
    "        fermentation_start_time = pd.Timestamp(ferm_begin[\"Timestamp\"])\n",
    "\n",
    "        # get booleans for new fermentation steps, where a new fermentation step is any step which exceeds the \n",
    "        # new fermentation time\n",
    "        new_fermentation_steps = (\n",
    "            brand_df[\"Timestamp\"].apply(lambda t: pd.Timestamp(t))\n",
    "            >= fermentation_start_time\n",
    "        )\n",
    "\n",
    "        # give each new fermentation step a new integer label\n",
    "        brand_df.loc[new_fermentation_steps, \"batch\"] = count + shift\n",
    "\n",
    "        # find time elapsed since start of fermentation, in units of float days\n",
    "        brand_df.loc[new_fermentation_steps, \"tsf\"] = brand_df.loc[\n",
    "            new_fermentation_steps, \"Timestamp\"\n",
    "        ].apply(\n",
    "            lambda t: (pd.Timestamp(t) - fermentation_start_time).total_seconds()\n",
    "            / 86400.0\n",
    "        )\n",
    "\n",
    "    # include only steps with non-negative \"batch\" labels and \"tsf\" not exceeding 100000 days\n",
    "    offset_df = brand_df[(brand_df[\"tsf\"] <= 100000) & (brand_df[\"batch\"] >= 0)]\n",
    "\n",
    "    # find the new label shift\n",
    "    shift = offset_df[\"batch\"].max()\n",
    "\n",
    "    return offset_df, shift\n",
    "print(\"--- fermentation_times defined ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00033-ca04b9c3-3752-40f9-a735-e0a7d8a822f8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:32:50.777609Z",
     "iopub.status.busy": "2020-08-14T19:32:50.765955Z",
     "iopub.status.idle": "2020-08-14T19:32:50.779881Z",
     "shell.execute_reply": "2020-08-14T19:32:50.779485Z"
    },
    "execution_millis": 118,
    "execution_start": 1642208804665,
    "output_cleared": false,
    "papermill": {
     "duration": 0.099512,
     "end_time": "2020-08-14T19:32:50.780030",
     "exception": false,
     "start_time": "2020-08-14T19:32:50.680518",
     "status": "completed"
    },
    "source_hash": "a941b3d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def no_batch_without_phase(offset_df, ref_df):\n",
    "\n",
    "    # find all batches represented in `ref_df`; these are valid batches\n",
    "    valid_batches = ref_df[\"batch\"].unique()\n",
    "\n",
    "    # we only want batches in `valid_batches`\n",
    "    # TODO: Complete the filter expression\n",
    "    # =========== STUDENT BEGIN ==========\n",
    "    offset_df = offset_df[@@@ Your code here @@@@.isin(@@@ Your code here @@@)]\n",
    "    # =========== STUDENT END ==========\n",
    "\n",
    "    return offset_df\n",
    "\n",
    "\n",
    "def organize_by_cooling(offset_df, fermentation_starts):\n",
    "    \"\"\"\n",
    "    DESCRIPTION: finds when cooling starts and then relabels statuses as being either in\n",
    "        'Precooling' or 'Cooling' stages. Necessary because entries may have been mislabelled.\n",
    "    RETURNS: relabeled offset_df\n",
    "    \"\"\"\n",
    "\n",
    "    # find events which are stictly in cooling stage. When cooling intensity (TIC OUT) exceeds 99.99 in\n",
    "    # the three vessel zones, the batch is in the cooling stage.\n",
    "    # TODO: Complete the expression\n",
    "    # =========== STUDENT BEGIN ==========\n",
    "    boolean = (\n",
    "        (offset_df[\"Top TIC OUT\"] > 99.99)\n",
    "        & (@@@ Your code here @@@)\n",
    "        & (@@@ Your code here @@@)\n",
    "    )\n",
    "    # =========== STUDENT END ==========\n",
    "\n",
    "    # filter for events which are strictly for cooling\n",
    "    strict_cooling_df = offset_df.loc[boolean, :]\n",
    "\n",
    "    # the start of cooling is the first instance of a strict cooling event for a batch (given by 'batch')\n",
    "    cooling_starts = strict_cooling_df.groupby(\"batch\").first().reset_index()\n",
    "\n",
    "    # filter out batches with no cooling stages so it won't be used for PCA\n",
    "    offset_df = no_batch_without_phase(offset_df, cooling_starts)\n",
    "\n",
    "    # if there are no batches with cooling stages, don't continue with data processing\n",
    "    if offset_df.empty:\n",
    "        raise NoCoolingStagesFound\n",
    "        return None, None\n",
    "    else:\n",
    "        print(f\"\\t{len(cooling_starts)} Cooling starts\")\n",
    "\n",
    "    # relabel batch statuses as either 'pre-cooling' or 'cooling'\n",
    "    for __, row in cooling_starts.iterrows():\n",
    "\n",
    "        # label for current batch\n",
    "        current_batch = row[\"batch\"]\n",
    "\n",
    "        # when cooling starts for current batch\n",
    "        cooling_start_time = row[\"tsf\"]\n",
    "\n",
    "        # get booleans for current batch\n",
    "        boolean = offset_df[\"batch\"] == current_batch\n",
    "\n",
    "        # Add a new \"Cooling_Stage\" column which is False or True for \"Precooling\" or \"Cooling\" respectively\n",
    "        # TODO: Complete the expression\n",
    "        # HINT: \"Cooling_Stage \" should be False if tsf < cooling start time, True otherwise\n",
    "        # =========== STUDENT BEGIN ==========\n",
    "         offset_df.loc[boolean, \"Cooling_Stage\"] = offset_df.loc[boolean, \"tsf\"].apply(\n",
    "            lambda t: @@@ Your code here @@@ if @@@ Your code here @@@  else True\n",
    "        )\n",
    "        # =========== STUDENT END ==========\n",
    "\n",
    "    return offset_df\n",
    "print(\"--- organize_by_cooling defined ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "00034-a17034d8-2176-49d5-990b-aae985452907",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:32:50.777609Z",
     "iopub.status.busy": "2020-08-14T19:32:50.765955Z",
     "iopub.status.idle": "2020-08-14T19:32:50.779881Z",
     "shell.execute_reply": "2020-08-14T19:32:50.779485Z"
    },
    "execution_millis": 47,
    "execution_start": 1642208804737,
    "output_cleared": false,
    "papermill": {
     "duration": 0.099512,
     "end_time": "2020-08-14T19:32:50.780030",
     "exception": false,
     "start_time": "2020-08-14T19:32:50.680518",
     "status": "completed"
    },
    "source_hash": "e27d8294",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Goal of the following definitions is from PCList, which is a list of pairs of the following format:\n",
    "#    (boolean, list of principal components)\n",
    "# to generate a list of booleans called PCA_df_selected which length is the concatenation of all\n",
    "# list of principal components in PCList. If a list in PCList has length > 1, the boolean value is\n",
    "# is copied for all element in the list\n",
    "#\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "PClist_unzip = [list(t) for t in zip(*PClist)]\n",
    "PC_columns_name = flatten(PClist_unzip[1])\n",
    "PCA_df_selected = []\n",
    "[PCA_df_selected.extend([x] * len(y)) for x, y in PClist]\n",
    "\n",
    "\n",
    "def summarize_by_batch(offset_df):\n",
    "    \"\"\"\n",
    "    DESCRIPTION: summarizes the time evolution of 10 attributes into 41 scalars.\n",
    "    RETURNS: dataframe containing summary of processed data for one brand in a\n",
    "        fermentor vessel.\n",
    "    \"\"\"\n",
    "\n",
    "    # get all unique batch labels available in offset_df\n",
    "    all_batches = offset_df[\"batch\"].unique()\n",
    "\n",
    "    # get number of batches available in offset_df\n",
    "    num_batches = len(all_batches)\n",
    "\n",
    "    # initialize a pandas dataframe with all elements as NaN (Not a Number)\n",
    "    PCA_df = pd.DataFrame(\n",
    "        data=np.zeros((num_batches, len(PC_columns_name))), columns=PC_columns_name\n",
    "    )\n",
    "    PCA_df[:] = np.nan\n",
    "\n",
    "    # fill PCA_df with summary of time series data per batch\n",
    "    for i, batch in enumerate(all_batches):\n",
    "\n",
    "        # divide offset_df for some given batch into cooling vs primary fermentation stages\n",
    "        # ferm_df has rows belonging to fermentation\n",
    "        #\n",
    "        ferm_df = offset_df[\n",
    "            (offset_df[\"batch\"] == batch)\n",
    "            & (offset_df[\"Status\"].isin(FERMENTATION_STAGES))\n",
    "        ]\n",
    "\n",
    "        # cool_df has rows belonging to cooling (i.e. \"Cooling_Stage\" is True) \n",
    "        # and to the current `batch` for ferm_df above\n",
    "        #\n",
    "        # TODO: Complete the filter expression\n",
    "        # =========== STUDENT BEGIN ==========\n",
    "        cool_df = offset_df[\n",
    "            (@@@ Your code here @@@ == batch) & (@@@ Your code here @@@ == True)\n",
    "        ]\n",
    "        # =========== STUDENT END ==========\n",
    "\n",
    "        # store batch, ADF, and column info in PCA_df\n",
    "        # select on active components according to PCList\n",
    "        #\n",
    "        PCA_df.iloc[i, 0] = brand_dictionary[ferm_df[\"Brand\"].iloc[0]]\n",
    "        PCA_df.iloc[i, 1] = batch\n",
    "        if PCA_df_selected[2]:\n",
    "            PCA_df.iloc[i, 2] = ferm_df[\"ADF\"].mean()  # average ADF in precooling stage\n",
    "        if PCA_df_selected[3]:\n",
    "            PCA_df.iloc[i, 3] = cool_df[\"ADF\"].mean()  # average ADF in cooling stage\n",
    "        if PCA_df_selected[4]:\n",
    "            # average Volume in cooling stage\n",
    "            PCA_df.iloc[i, 4] = cool_df[\"Volume\"].mean()\n",
    "\n",
    "        if PCA_df_selected[5]:\n",
    "            # summaraize data in primary fermentation stages\n",
    "            PCA_df.iloc[i, 5] = ferm_df[\"tsf\"].max()  # duration of precooling stages\n",
    "        if PCA_df_selected[6]:\n",
    "            # average values of temperature and cooling intensity for each zone during precooling\n",
    "            PCA_df.iloc[i, 6:9] = [\n",
    "                ferm_df[c].mean(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_OUT_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[9]:\n",
    "            # average values of temperature and cooling intensity for each zone during precooling\n",
    "            PCA_df.iloc[i, 9:12] = [\n",
    "                ferm_df[c].mean(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[12]:\n",
    "            # maximum temperature for each zone during precooling\n",
    "            PCA_df.iloc[i, 12:15] = [\n",
    "                ferm_df[c].max(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[15]:\n",
    "            # minimum temperature for each zone during precooling\n",
    "            PCA_df.iloc[i, 15:18] = [\n",
    "                ferm_df[c].min(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[18]:\n",
    "            # variance of the temperature of each zone cureing precooling\n",
    "            PCA_df.iloc[i, 18:21] = [\n",
    "                ferm_df[c].var(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[21]:\n",
    "            # average of the variance of the temperatures in each zone during precooling\n",
    "            PCA_df.iloc[i, 21] = (ferm_df[TIC_PV_COLUMNS].var(axis=1)).mean()\n",
    "\n",
    "        # summarize data in cooling stages\n",
    "        if PCA_df_selected[22]:\n",
    "            # duration of cooling stages\n",
    "            PCA_df.iloc[i, 22] = cool_df[\"tsf\"].max() - cool_df[\"tsf\"].min()\n",
    "        if PCA_df_selected[23]:\n",
    "            # average values of temperature and cooling intensity for each zone during cooling\n",
    "            PCA_df.iloc[i, 23:26] = [\n",
    "                cool_df[c].mean(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_OUT_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[26]:\n",
    "            # average values of temperature and cooling intensity for each zone during cooling\n",
    "            PCA_df.iloc[i, 26:29] = [\n",
    "                cool_df[c].mean(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[29]:\n",
    "            # maximum temperature for each zone during cooling\n",
    "            PCA_df.iloc[i, 29:32] = [  # list(cool_df[TIC_PV_COLUMNS].max(axis=0\n",
    "                cool_df[c].max(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[32]:\n",
    "            # minimum temperature for each zone during cooling\n",
    "            PCA_df.iloc[i, 32:35] = [  # list(cool_df[TIC_PV_COLUMNS].min(axis=0))\n",
    "                cool_df[c].min(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[35]:\n",
    "            # variance of the temperature of each zone during cooling\n",
    "            PCA_df.iloc[i, 35:38] = [  # list(cool_df[TIC_PV_COLUMNS].var(axis=0))\n",
    "                cool_df[c].var(axis=0) if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "        if PCA_df_selected[38]:\n",
    "            # average of the variance of the temperatures in each zone during cooling\n",
    "            PCA_df.iloc[i, 38] = (cool_df[TIC_PV_COLUMNS].var(axis=1)).mean()\n",
    "        if PCA_df_selected[39]:\n",
    "            # initial temperature in cooling stage\n",
    "            PCA_df.iloc[i, 39:42] = [  # list(cool_df[TIC_PV_COLUMNS].iloc[0])\n",
    "                cool_df[c].iloc[0] if position_active[ci] else np.nan\n",
    "                for ci, c in enumerate(TIC_PV_COLUMNS)\n",
    "            ]\n",
    "\n",
    "    return PCA_df\n",
    "print(\"--- summarize_by_batch defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-3a2e7e8f-1c1e-43ee-8ce0-8facc5c98b76",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.118854,
     "end_time": "2020-08-14T19:32:50.973351",
     "exception": false,
     "start_time": "2020-08-14T19:32:50.854497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Part 4. Process and Summarize Data \n",
    "---\n",
    "<a id=’section_4’></a>\n",
    "\n",
    "Run the cell below to call the previously defined utility functions and  create the dataframe `FeatureDF` which contains a summary of the time series data from `all_brands_df`. \n",
    "\n",
    "The columns of `FeatureDF` can be used as input features for Principal Component Analysis (PCA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "00036-30120799-2972-45b7-8c37-2b1c232cbaa9",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     177
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:32:51.258873Z",
     "iopub.status.busy": "2020-08-14T19:32:51.258080Z",
     "iopub.status.idle": "2020-08-14T19:33:29.458746Z",
     "shell.execute_reply": "2020-08-14T19:33:29.459908Z"
    },
    "execution_millis": 66361,
    "execution_start": 1642208804815,
    "output_cleared": false,
    "papermill": {
     "duration": 38.349672,
     "end_time": "2020-08-14T19:33:29.460133",
     "exception": false,
     "start_time": "2020-08-14T19:32:51.110461",
     "status": "completed"
    },
    "source_hash": "ccd892bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize dataframe which will be later saved into .csv format to be analyzed by PCA\n",
    "FeatureDF = pd.DataFrame(columns=PC_columns_name)\n",
    "\n",
    "# initialize batch labels\n",
    "label_shift = 1\n",
    "\n",
    "generator = ((f, b) for f in FERMENTORS_OF_INTEREST for b in BRANDS_OF_INTEREST)\n",
    "for fermentor, brand in generator:\n",
    "    print(f\"\\n===> FV {fermentor}. Brand: {brand}\")\n",
    "\n",
    "    # create reduced df containing only data from relevant vessel and brand\n",
    "    brand_df = all_brands_df[\n",
    "        (all_brands_df[\"Asset_Id\"] == fermentor) \n",
    "        & (all_brands_df[\"Brand\"] == brand)\n",
    "    ]\n",
    "    \n",
    "    # identify fermentation starts\n",
    "    fermentation_starts = brand_df[\n",
    "        (brand_df[\"Status\"] == \"Fermentation\")\n",
    "        & (brand_df[\"Status\"].shift(1) != \"Fermentation\")\n",
    "    ]\n",
    "    \n",
    "    # dont' consider data not in important brewing stages\n",
    "    brand_df = brand_df[brand_df[\"Status\"].isin(IMPORTANT_BREWING_STAGES)]\n",
    "    \n",
    "    # if fermentation did not occur, there is nothing to analyze\n",
    "    N_fermentations = len(fermentation_starts)\n",
    "    if N_fermentations == 0:\n",
    "        print (\"\\tNo Fermentation data to analyze!\")\n",
    "        continue\n",
    "    else:\n",
    "        print (f\"\\t{N_fermentations} Fermentation starts\")\n",
    "        \n",
    "    # offset timestamps for brand_df, so t=0 when fermentation starts. \n",
    "    offset_df, shift = fermentation_times(brand_df, fermentation_starts, shift=label_shift)\n",
    "    \n",
    "    # also assign new labels for each brew batch\n",
    "    label_shift = shift+1\n",
    "    \n",
    "    # remove batches with no maturation phases\n",
    "    offset_df = no_batch_without_phase(offset_df, offset_df[offset_df[\"Status\"] == \"Maturation\"])\n",
    "    \n",
    "    # identify cooling starts; relabel relabel all Statuses before \"Cooling\" as \"Pre-cooling\"\n",
    "    # if cooling stages do not exist, pca not needed to determine whether batch is bad\n",
    "    try:\n",
    "        offset_df = organize_by_cooling(offset_df, fermentation_starts)\n",
    "    except NoCoolingStagesFound:\n",
    "        print (\"\\tNo Cooling data to analyze!\")\n",
    "        continue\n",
    "        \n",
    "    # summarize time series data into compact dataframe\n",
    "    FeatureDF = FeatureDF.append(summarize_by_batch(offset_df))\n",
    "    \n",
    "# clean indices and remove unused columns \n",
    "FeatureDF = FeatureDF.reset_index()\n",
    "FeatureDF = FeatureDF.drop(columns=\"index\")\n",
    "FeatureDF = FeatureDF.dropna(axis=1)\n",
    "        \n",
    "# write `FeatureDF` to .csv data file\n",
    "FeatureDF.to_csv(\"FeatureDF.csv\", sep=\",\", index=False)\n",
    "\n",
    "# preview processed data\n",
    "print(\"\\n\\nFinished data processing. `FeatureDF` looks like:\")\n",
    "FeatureDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00037-50dfa781-6711-4929-862e-4ae451e8f1c0",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.300061,
     "end_time": "2020-08-14T19:33:30.082699",
     "exception": false,
     "start_time": "2020-08-14T19:33:29.782638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Part 5. Apply PCA to `FeatureDF`\n",
    "---\n",
    "<a id=’section_5’></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00038-86ff0800-602a-46d0-90c8-ed93cf95bc1d",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.448367,
     "end_time": "2020-08-14T19:33:30.737839",
     "exception": false,
     "start_time": "2020-08-14T19:33:30.289472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5a. Define and scale the feature space\n",
    "<a ia=’section_5a’></a>\n",
    "The feature space `X` contains all the input features (i.e. columns) in `FeatureDF` which can potentially affect the flavor profile of the beers. \n",
    "\n",
    "When PCA is applied on `X`, we obtain new set of coordinates (\"principal components\") which are orthogonal to each other and point in the directions of maximum variance (eigenvectors).\n",
    "\n",
    "To prevent any one feature dominating the variance calculations, it is recommended that the feature space `X` be scaled. \n",
    "\n",
    "In this case, the feature space `X` is scaled by \"centering\" each feature and normalizing them by their standard deviation. Using sklearn, this can be accomplished using `StandardScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00039-8af3827e-a586-4793-be5b-b816f7792250",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:31.306455Z",
     "iopub.status.busy": "2020-08-14T19:33:31.305016Z",
     "iopub.status.idle": "2020-08-14T19:33:31.309616Z",
     "shell.execute_reply": "2020-08-14T19:33:31.310147Z"
    },
    "execution_millis": 17,
    "execution_start": 1642208871181,
    "output_cleared": false,
    "papermill": {
     "duration": 0.098679,
     "end_time": "2020-08-14T19:33:31.310287",
     "exception": false,
     "start_time": "2020-08-14T19:33:31.211608",
     "status": "completed"
    },
    "source_hash": "ad913069",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the feature space (variables which affect beer quality)\n",
    "X = FeatureDF.iloc[:, 2:]\n",
    "\n",
    "# M = number of observations (rows in X),  N = number of components in the feature space (columns in X)\n",
    "[M, N] = np.shape(X)\n",
    "\n",
    "# save unscaled feature space (will only be use for plotting purposes)\n",
    "Xold = X\n",
    "\n",
    "# scale the feature space\n",
    "X = StandardScaler().fit_transform(X)\n",
    "print(\"--- feature space defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00040-18e05df7-031c-4152-bf98-072fcae09983",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.090908,
     "end_time": "2020-08-14T19:33:31.481152",
     "exception": false,
     "start_time": "2020-08-14T19:33:31.390244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**>>>>>===================THIS NEXT IMMEDIATE CELL CAN BE IGNORED===================**\n",
    "\n",
    "Run the cell below to graphically compare the difference between scaled and unscaled features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "00041-34e26b86-c632-4d5f-b21f-c396d8601c2d",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     527,
     527
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:31.654699Z",
     "iopub.status.busy": "2020-08-14T19:33:31.653823Z",
     "iopub.status.idle": "2020-08-14T19:33:31.812709Z",
     "shell.execute_reply": "2020-08-14T19:33:31.813228Z"
    },
    "execution_millis": 341,
    "execution_start": 1642208871200,
    "output_cleared": false,
    "papermill": {
     "duration": 0.249045,
     "end_time": "2020-08-14T19:33:31.813376",
     "exception": false,
     "start_time": "2020-08-14T19:33:31.564331",
     "status": "completed"
    },
    "source_hash": "aa714a8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plotting function\n",
    "def create_box_plot_object(feature_matrix, N_features, title, legend):\n",
    "    # print(\"cols=\", feature_matrix.columns)\n",
    "    plot_objects = []\n",
    "    for i in range(N_features):\n",
    "        plot_obj = go.Box(y=np.array(feature_matrix)[:, i], name=legend[i])\n",
    "        plot_objects.append(plot_obj)\n",
    "\n",
    "    fig = go.Figure(data=plot_objects, layout=go.Layout(title=title))\n",
    "    fig.show()\n",
    "    return\n",
    "\n",
    "# create a plotly object for the unscaled feature space\n",
    "create_box_plot_object(Xold, N, \"Unscaled Features\", list(Xold.columns))\n",
    "\n",
    "# create a plotly object for the scaled feature space\n",
    "create_box_plot_object(X, N, \"Scaled Features\", list(Xold.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00042-ad0719d7-6beb-438e-b73b-fdd970d7843d",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.150402,
     "end_time": "2020-08-14T19:33:32.109469",
     "exception": false,
     "start_time": "2020-08-14T19:33:31.959067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**===========================END IGNORABLE CELL===========================<<<<<**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00043-fdb37c5f-de7c-4af9-b04f-a6fd76e6af38",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.16644,
     "end_time": "2020-08-14T19:33:32.434408",
     "exception": false,
     "start_time": "2020-08-14T19:33:32.267968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5b. Apply PCA to the feature space\n",
    "<a id=’section_5b’></a>\n",
    "\n",
    "When PCA is applied to the old feature space `X`, we can obtain a covariance (or correlation) matrix and subsequently eigenvectors and eigenvalues.\n",
    "\n",
    "The eigenvectors, or \"Principal Axes\", point in the directions of the new feature space, `T`, and in the directions of maximum variance of the old feature space `X`.\n",
    "\n",
    "The eigenvalues,`Lambda`, correspond the the magnitude of the Principal Axes. The eigenvalues reflect the amount of variance explained by the Principal Axes.\n",
    "\n",
    "The new feature space `T` is a matrix of \"scores\" or \"Principal Components\". Each Principal Component is a linear combination of the input features in `X`.\n",
    "\n",
    "The coefficients for these linear combinations are the elements of their corresponding Principal Axes or eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "00044-5c9b4c49-57ce-4f9a-81ef-aa4fe8967c62",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:32.772441Z",
     "iopub.status.busy": "2020-08-14T19:33:32.770723Z",
     "iopub.status.idle": "2020-08-14T19:33:32.773998Z",
     "shell.execute_reply": "2020-08-14T19:33:32.773506Z"
    },
    "execution_millis": 26,
    "execution_start": 1642208871549,
    "output_cleared": false,
    "papermill": {
     "duration": 0.176071,
     "end_time": "2020-08-14T19:33:32.774106",
     "exception": false,
     "start_time": "2020-08-14T19:33:32.598035",
     "status": "completed"
    },
    "source_hash": "b067becd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# obtain maximum number of principal components\n",
    "n_comps = min([M, N])\n",
    "\n",
    "# initialize PCA and get covariance matrix\n",
    "covariance_matrix = PCA(n_components=n_comps)\n",
    "covariance_matrix.fit(X)\n",
    "\n",
    "# get matrix of principal components (a.k.a PCs or scores)\n",
    "T = covariance_matrix.transform(X)\n",
    "\n",
    "# get eigenvectors\n",
    "P = covariance_matrix.components_\n",
    "\n",
    "# get eigenvalues\n",
    "Lambda = covariance_matrix.explained_variance_\n",
    "print(\"--- cell ok ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00045-6be107bf-21b9-406c-92f4-a91445807825",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.181698,
     "end_time": "2020-08-14T19:33:33.110015",
     "exception": false,
     "start_time": "2020-08-14T19:33:32.928317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**>>>>>===================THIS NEXT IMMEDIATE CELL CAN BE IGNORED===================**\n",
    "\n",
    "Visualize the first $n$ components and how they are related to the input features (columns in `FeatureDF`). A principal component is a linear combination of the input features, and the coefficients are the elements of its eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "00046-7f935548-0f89-4241-9a1e-29137b388c33",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:33.404798Z",
     "iopub.status.busy": "2020-08-14T19:33:33.403778Z",
     "iopub.status.idle": "2020-08-14T19:33:33.431395Z",
     "shell.execute_reply": "2020-08-14T19:33:33.431878Z"
    },
    "execution_millis": 472,
    "execution_start": 1642208871579,
    "output_cleared": false,
    "papermill": {
     "duration": 0.171892,
     "end_time": "2020-08-14T19:33:33.432058",
     "exception": false,
     "start_time": "2020-08-14T19:33:33.260166",
     "status": "completed"
    },
    "source_hash": "afd5fc15",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# appropriate number of princiapl components to use\n",
    "first_n_components = 3\n",
    "\n",
    "# initialize plots\n",
    "fig = make_subplots(\n",
    "    rows=first_n_components, cols=1, shared_xaxes=True, vertical_spacing=0.03\n",
    ")\n",
    "\n",
    "for i_component in range(first_n_components):\n",
    "    plot_object = go.Bar(\n",
    "        x=FeatureDF.columns.tolist()[2:],\n",
    "        y=P[i_component, :],\n",
    "        name=f\"PC{i_component+1}\",\n",
    "    )\n",
    "\n",
    "    fig.append_trace(plot_object, i_component + 1, 1)\n",
    "    fig[\"layout\"][f\"yaxis{i_component+1}\"].update(title=\"Coefficients\")\n",
    "fig[\"layout\"].update(width=800, height=800, xaxis=dict(tickangle=45))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00047-87ea5ce0-f4fc-474a-b061-fd18cf165604",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.14893,
     "end_time": "2020-08-14T19:33:33.717130",
     "exception": false,
     "start_time": "2020-08-14T19:33:33.568200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**===========================END IGNORABLE CELL===========================<<<<<**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00048-a666febc-7586-4280-8431-d44822057a77",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.166898,
     "end_time": "2020-08-14T19:33:34.023801",
     "exception": false,
     "start_time": "2020-08-14T19:33:33.856903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5c. Find number of principal components sufficent to explain data\n",
    "<a id=’section_5c’></a>\n",
    "The eigenvalues of the covariance matrix is equivalent to the variance of a component. We want $l$ components which explain most of the variance in the data. A simple and widely used criterion is the cumulative percent variance (CPV).\n",
    "\n",
    "$ \n",
    "CPV(l) = 100 \\left( \n",
    "\\frac{\\sum_{j=1}^l \\lambda_j}\n",
    "{\\sum_{j=1}^M \\lambda_j} \n",
    "\\right) \\%\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "00049-b2f69858-755c-4067-8062-cc19c6258998",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     502
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:34.726456Z",
     "iopub.status.busy": "2020-08-14T19:33:34.725568Z",
     "iopub.status.idle": "2020-08-14T19:33:34.757585Z",
     "shell.execute_reply": "2020-08-14T19:33:34.758525Z"
    },
    "execution_millis": 80,
    "execution_start": 1642208872064,
    "output_cleared": false,
    "papermill": {
     "duration": 0.436452,
     "end_time": "2020-08-14T19:33:34.758764",
     "exception": false,
     "start_time": "2020-08-14T19:33:34.322312",
     "status": "completed"
    },
    "source_hash": "b9d025de",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the variance explained by each component, normalize it, and take the cumulative sum\n",
    "cumulative_variance = covariance_matrix.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# plotly object for cumulative variance data\n",
    "data = go.Scatter(\n",
    "    x=[item + 1 for item in range(len(cumulative_variance))],\n",
    "    y=[100.0 * item for item in list(cumulative_variance)],\n",
    "    mode=\"lines+markers\",\n",
    ")\n",
    "\n",
    "# plotly object for reference CPV\n",
    "lines = []\n",
    "for var in [75, 87, 99]:\n",
    "    lines.append(\n",
    "        go.Scatter(\n",
    "            x=[0] + [item + 1 for item in range(len(cumulative_variance))],\n",
    "            y=[var] * (len(cumulative_variance) + 1),\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"red\", dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# plot layout\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(title=\"Number of Principal Components\"),\n",
    "    yaxis=dict(title=\"Cumulative Variance (%)\"),\n",
    "    height=500,\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "# create and show plot\n",
    "fig = go.Figure(data=[data] + lines, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "00050-52e27e4f-8383-4732-9b1c-b3a4a5fcb977",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     33.1875,
     167.59375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1642208872159,
    "output_cleared": false,
    "papermill": {
     "duration": 0.314337,
     "end_time": "2020-08-14T19:33:35.311912",
     "exception": false,
     "start_time": "2020-08-14T19:33:34.997575",
     "status": "completed"
    },
    "source_hash": "af8bed99",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"**Question: How many PCs do you think you should use?**\"))\n",
    "# =========== STUDENT BEGIN ==========\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "@@@ Your answer here @@@\n",
    "\"\"\"))\n",
    "# =========== STUDENT END =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00051-65378da0-53e6-4d5c-8551-b51c6cdd6e40",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.226071,
     "end_time": "2020-08-14T19:33:35.774833",
     "exception": false,
     "start_time": "2020-08-14T19:33:35.548762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5d. Visualize Deschutes data using the principal components\n",
    "<a id='section_5d'></a>\n",
    "Regardless of the appropriate number of principal components from CPV, we are limited to visualizing at most three principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "00052-657e99a1-a6d8-4c0f-a6af-d8d61ec6ca87",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:36.080189Z",
     "iopub.status.busy": "2020-08-14T19:33:36.079304Z",
     "iopub.status.idle": "2020-08-14T19:33:36.123864Z",
     "shell.execute_reply": "2020-08-14T19:33:36.124520Z"
    },
    "execution_millis": 68,
    "execution_start": 1642208872177,
    "output_cleared": false,
    "papermill": {
     "duration": 0.206687,
     "end_time": "2020-08-14T19:33:36.124686",
     "exception": false,
     "start_time": "2020-08-14T19:33:35.917999",
     "status": "completed"
    },
    "source_hash": "ba614fb8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize list for plot objects\n",
    "obj_list = []\n",
    "\n",
    "# create plot objects for each brand\n",
    "for i_brand, brand in enumerate(BRANDS_OF_INTEREST):\n",
    "\n",
    "    # get which entries in ProcessedData correspond to rband\n",
    "    boolean = FeatureDF[\"Brand\"] == brand_dictionary[brand]\n",
    "\n",
    "    # create plotly object\n",
    "    plot_obj = go.Scatter3d(\n",
    "        x=T[boolean, 0],\n",
    "        y=T[boolean, 1],\n",
    "        z=T[boolean, 2],\n",
    "        text=list(FeatureDF.loc[boolean, \"Batch\"]),\n",
    "        hoverinfo=\"text\",\n",
    "        hovertemplate=\"Batch %{text:2.0}\",\n",
    "        name=brand + f\" ({boolean.sum()})\",\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=7, opacity=0.75),\n",
    "    )\n",
    "\n",
    "    # append to list of plotly objects\n",
    "    obj_list.append(plot_obj)\n",
    "print(\"--- cell ok ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "00053-2e44b605-a80e-440e-ab77-af9ca294e4c2",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     602
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:36.080189Z",
     "iopub.status.busy": "2020-08-14T19:33:36.079304Z",
     "iopub.status.idle": "2020-08-14T19:33:36.123864Z",
     "shell.execute_reply": "2020-08-14T19:33:36.124520Z"
    },
    "execution_millis": 152,
    "execution_start": 1642208872250,
    "output_cleared": false,
    "papermill": {
     "duration": 0.206687,
     "end_time": "2020-08-14T19:33:36.124686",
     "exception": false,
     "start_time": "2020-08-14T19:33:35.917999",
     "status": "completed"
    },
    "source_hash": "194c277b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create layout\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=\"PC 1\"), yaxis=dict(title=\"PC 2\"), zaxis=dict(title=\"PC 3\")\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=0),\n",
    "    legend=dict(x=1.0, y=0.5),\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# plot!\n",
    "fig = go.Figure(data=obj_list, layout=layout)\n",
    "fig.update_layout(\n",
    "    title_text=f\"<br>PCA scatterplot for the 4 brands {BRANDS_OF_INTEREST}<br> with most data\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00054-448241ec-d34c-4849-aa42-0d6238ee8e69",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.180996,
     "end_time": "2020-08-14T19:33:36.663963",
     "exception": false,
     "start_time": "2020-08-14T19:33:36.482967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5e. What's in an outlier?\n",
    "<a id=’section_5e’></a>\n",
    "We can use **contribution plots** to identify which input features are responsible for making an outlier an outlier. One can create a contribution plot for some given PC and some given observation (i.e. a beer batch). \n",
    "\n",
    "We want to compare how the contributions from an outlier differ from the contributions of in-spec batches. To do this, we need the batch label(s) for the outlier(s) and in-spec/reference batches.\n",
    "\n",
    "A contribution of an input feature to a PC for a given observation is the value of the input feature at that observation times its coefficient (element of eignevector for the PC).\n",
    "\n",
    "To find the batch labels, hover over the data points in the 3-D scatter plot found in Part 5d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "00055-a53d9f59-b2c9-49fd-b7a3-26a579405b8a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:37.061771Z",
     "iopub.status.busy": "2020-08-14T19:33:37.049090Z",
     "iopub.status.idle": "2020-08-14T19:33:37.096945Z",
     "shell.execute_reply": "2020-08-14T19:33:37.097557Z"
    },
    "execution_millis": 1,
    "execution_start": 1642208872417,
    "output_cleared": false,
    "papermill": {
     "duration": 0.247015,
     "end_time": "2020-08-14T19:33:37.097730",
     "exception": false,
     "start_time": "2020-08-14T19:33:36.850715",
     "status": "completed"
    },
    "source_hash": "84055be9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick a brand to analyze\n",
    "brand = \"Grey Horse\"\n",
    "\n",
    "# identify the batch label for outlier point(s) - has to be a list!\n",
    "outlier_batches = [184]\n",
    "\n",
    "############### >>>>> DO NOT CHANGE SECTION - START >>>>> #############\n",
    "# filter out irrelevant brands\n",
    "all_brand_batches = FeatureDF[FeatureDF[\"Brand\"] == brand_dictionary[brand]]\n",
    "\n",
    "# identify labels for in-spec batches\n",
    "inspec_batches = [\n",
    "    x for x in all_brand_batches[\"Batch\"].unique() if x not in outlier_batches\n",
    "]\n",
    "\n",
    "\n",
    "def extract_feature_values(ref_lbls, feat_matrix=X, feat_df=FeatureDF):\n",
    "    ref_idxs = []\n",
    "    for idx, lbl in enumerate(ref_lbls):\n",
    "        ref_idxs.append(feat_df.index[feat_df[\"Batch\"] == lbl].tolist()[0])\n",
    "    feature_values = list(feat_matrix[ref_idxs, :].mean(axis=0))\n",
    "    return feature_values\n",
    "\n",
    "\n",
    "print(\"--- cell ok ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": "00056-59967122-6c80-4e96-b928-ab9ef4f84514",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:37.061771Z",
     "iopub.status.busy": "2020-08-14T19:33:37.049090Z",
     "iopub.status.idle": "2020-08-14T19:33:37.096945Z",
     "shell.execute_reply": "2020-08-14T19:33:37.097557Z"
    },
    "execution_millis": 3368476579,
    "execution_start": 1642208872435,
    "output_cleared": false,
    "papermill": {
     "duration": 0.247015,
     "end_time": "2020-08-14T19:33:37.097730",
     "exception": false,
     "start_time": "2020-08-14T19:33:36.850715",
     "status": "completed"
    },
    "source_hash": "3f01f15c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_plot_object(\n",
    "    eigenvector,\n",
    "    feature_values,\n",
    "    bar_color,\n",
    "    feature_name,\n",
    "    show_legend=True,\n",
    "    feature_df=FeatureDF,\n",
    "    N_PCs=3,\n",
    "):\n",
    "    # compute feature contribution\n",
    "    contribution = [p * x for p, x in zip(eigenvector, feature_values)]\n",
    "\n",
    "    # create plot object for the contribution\n",
    "    plot_object = go.Bar(\n",
    "        x=feature_df.columns.tolist()[2:],\n",
    "        y=contribution,\n",
    "        name=feature_name,\n",
    "        marker=dict(color=bar_color),\n",
    "        showlegend=show_legend,\n",
    "    )\n",
    "    return plot_object\n",
    "\n",
    "\n",
    "print(\"--- create_plot_object defined ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "00057-164e07bc-9cfc-443c-aba3-767a42e7b42a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:37.061771Z",
     "iopub.status.busy": "2020-08-14T19:33:37.049090Z",
     "iopub.status.idle": "2020-08-14T19:33:37.096945Z",
     "shell.execute_reply": "2020-08-14T19:33:37.097557Z"
    },
    "execution_millis": 8,
    "execution_start": 1642208872450,
    "output_cleared": false,
    "papermill": {
     "duration": 0.247015,
     "end_time": "2020-08-14T19:33:37.097730",
     "exception": false,
     "start_time": "2020-08-14T19:33:36.850715",
     "status": "completed"
    },
    "source_hash": "14ea36d9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_feature_contributions(\n",
    "    outlier_feature_vals, ref_feature_vals, eigenvector_matrix=P\n",
    "):\n",
    "\n",
    "    # initialize contribution plots\n",
    "    fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.03)\n",
    "\n",
    "    # create plot objects for contributions in first 3 PCs\n",
    "    for i_component in range(3):\n",
    "\n",
    "        # flag, whether to show legend\n",
    "        show_flag = True if i_component == 0 else False\n",
    "\n",
    "        # eigenvector for PC\n",
    "        eigenvector = eigenvector_matrix[i_component, :]\n",
    "\n",
    "        # create plot object for outlier batch(es)\n",
    "        outlier_obj = create_plot_object(\n",
    "            eigenvector,\n",
    "            outlier_feature_vals,\n",
    "            \"royalblue\",\n",
    "            \"Outlier\",\n",
    "            show_legend=show_flag,\n",
    "        )\n",
    "\n",
    "        # create plot object for inspec batch(es)\n",
    "        ref_obj = create_plot_object(\n",
    "            eigenvector,\n",
    "            ref_feature_vals,\n",
    "            \"lightsteelblue\",\n",
    "            \"In-spec\",\n",
    "            show_legend=show_flag,\n",
    "        )\n",
    "\n",
    "        # create bar plot for PC contribution\n",
    "        fig.append_trace(outlier_obj, i_component + 1, 1)\n",
    "        fig.append_trace(ref_obj, i_component + 1, 1)\n",
    "\n",
    "        # label y axis appropriately\n",
    "        fig[\"layout\"][f\"yaxis{i_component+1}\"].update(\n",
    "            title=f\"PC{i_component+1} Contribution\"\n",
    "        )\n",
    "\n",
    "    # layout of bar plot\n",
    "    fig[\"layout\"].update(width=800, height=900, xaxis=dict(tickangle=45))\n",
    "\n",
    "    # show bar plot\n",
    "    fig.show()\n",
    "    return\n",
    "\n",
    "print(\"--- plot_feature_contributions defined ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "00058-d15580c9-06f2-43bd-86d1-7cb1ba29a5b5",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:37.061771Z",
     "iopub.status.busy": "2020-08-14T19:33:37.049090Z",
     "iopub.status.idle": "2020-08-14T19:33:37.096945Z",
     "shell.execute_reply": "2020-08-14T19:33:37.097557Z"
    },
    "execution_millis": 318,
    "execution_start": 1642208872463,
    "output_cleared": false,
    "papermill": {
     "duration": 0.247015,
     "end_time": "2020-08-14T19:33:37.097730",
     "exception": false,
     "start_time": "2020-08-14T19:33:36.850715",
     "status": "completed"
    },
    "source_hash": "974f7c62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### <<<<< DO NOT CHANGE SECTION - END <<<<< #############\n",
    "\n",
    "# call function extract feature values\n",
    "outlier_feature_values = extract_feature_values(outlier_batches)\n",
    "inspec_feature_values = extract_feature_values(inspec_batches)\n",
    "\n",
    "# call function to plot contributions\n",
    "plot_feature_contributions(outlier_feature_values, inspec_feature_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00059-2aec86e0-d9db-447e-ac4c-26c04f67bdd3",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.196276,
     "end_time": "2020-08-14T19:33:37.487778",
     "exception": false,
     "start_time": "2020-08-14T19:33:37.291502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Highlight outlier rows in FeatureDF.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00060-d025dd3b-1ff6-4bc7-a34f-6b9489e2dd72",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     606.546875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:37.843564Z",
     "iopub.status.busy": "2020-08-14T19:33:37.842319Z",
     "iopub.status.idle": "2020-08-14T19:33:38.171120Z",
     "shell.execute_reply": "2020-08-14T19:33:38.170525Z"
    },
    "execution_millis": 3374,
    "execution_start": 1642208872609,
    "output_cleared": false,
    "papermill": {
     "duration": 0.503624,
     "end_time": "2020-08-14T19:33:38.171257",
     "exception": false,
     "start_time": "2020-08-14T19:33:37.667633",
     "status": "completed"
    },
    "source_hash": "9f9b9c76",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the save feature dataframe\n",
    "feature_df = pd.read_csv(\"FeatureDF.csv\")\n",
    "feature_df = feature_df.astype({\"Batch\": int})\n",
    "\n",
    "# Filter on index+1 in BRANDS_OF_INTEREST (because brand in FeatureDF.csv is an integer)\n",
    "brand_df = feature_df[feature_df[\"Brand\"] == BRANDS_OF_INTEREST.index(brand) + 1]\n",
    "\n",
    "# row turns red for batch flagged as outlier\n",
    "def highlight_outliers(s):\n",
    "    if s.Batch in outlier_batches:\n",
    "        return [\"background-color: red\"] * 10\n",
    "    else:\n",
    "        return [\"\"] * 10\n",
    "\n",
    "\n",
    "brand_df.style.apply(highlight_outliers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00061-08f564a3-a636-483c-959c-f3f6983af5a7",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     38.5,
     33.1875,
     90.765625,
     33.1875,
     33.1875,
     33.1875,
     109.96875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 18,
    "execution_start": 1642208876001,
    "output_cleared": false,
    "papermill": {
     "duration": 0.207119,
     "end_time": "2020-08-14T19:33:38.576050",
     "exception": false,
     "start_time": "2020-08-14T19:33:38.368931",
     "status": "completed"
    },
    "source_hash": "de027138",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"### QUESTIONS:\"))\n",
    "display(Markdown(\"**1. Why do you think there are bad batches?**\"))\n",
    "# =========== STUDENT BEGIN ==========\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "@@@ Your answer here @@@\n",
    "\"\"\"))\n",
    "# =========== STUDENT END ==========\n",
    "\n",
    "display(Markdown(\"**2. Does it seem like there is equipment failure at some point?**\"))\n",
    "# =========== STUDENT BEGIN ==========\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "@@@ Your answer here @@@\n",
    "\"\"\"))\n",
    "# =========== STUDENT END ==========\n",
    "\n",
    "display(Markdown(\"**3. What would you do to determine the root cause of a process or equipment failure?**\"))\n",
    "# =========== STUDENT BEGIN ==========\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "@@@ Your answer here @@@\n",
    "\"\"\"))\n",
    "# =========== STUDENT END =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00062-4c8535ab-c527-42cf-a264-d6553e225445",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.318298,
     "end_time": "2020-08-14T19:33:39.240545",
     "exception": false,
     "start_time": "2020-08-14T19:33:38.922247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Part 6. Apply clustering to Principal Components (BONUS)\n",
    "---\n",
    "<a id=’section_6’></a>\n",
    "There are many clustering algorithms which are available. One of the most commonly used is **k-means clustering**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00063-2668ba9f-18dc-4f8a-85c4-cb23d3a26cf9",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.160135,
     "end_time": "2020-08-14T19:33:39.635753",
     "exception": false,
     "start_time": "2020-08-14T19:33:39.475618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6a. Apply k-means clustering on the principal components\n",
    "<a id=’section_6a’></a>\n",
    "We use the cumulative variance plot to decide on an appropriate number (\"most dominant\") of principal components, and we perform k-means clustering only those components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00064-1046eabd-006b-4828-9bdc-d7e114782e00",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:40.170322Z",
     "iopub.status.busy": "2020-08-14T19:33:40.169249Z",
     "iopub.status.idle": "2020-08-14T19:33:40.292786Z",
     "shell.execute_reply": "2020-08-14T19:33:40.293280Z"
    },
    "execution_millis": 630,
    "execution_start": 1642208876032,
    "output_cleared": true,
    "papermill": {
     "duration": 0.468116,
     "end_time": "2020-08-14T19:33:40.293528",
     "exception": false,
     "start_time": "2020-08-14T19:33:39.825412",
     "status": "completed"
    },
    "source_hash": "1d95a1a9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base this on CPV plot\n",
    "n_principal_components = 4\n",
    "\n",
    "# number of clusters = number of available beer brands\n",
    "K = len(FeatureDF[\"Brand\"].unique())\n",
    "\n",
    "# apply kmeans on principal components\n",
    "kmeans = KMeans(n_clusters=K).fit(T[:, :n_principal_components])\n",
    "\n",
    "# find which cluster each beer batch belongs to\n",
    "cluster_id = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00065-4372574b-a854-4d9e-b719-30f95c97ef6b",
    "deepnote_cell_type": "markdown",
    "papermill": {
     "duration": 0.185724,
     "end_time": "2020-08-14T19:33:40.781563",
     "exception": false,
     "start_time": "2020-08-14T19:33:40.595839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6b. Plot principal components and color by kmeans cluster\n",
    "<a id=’section_6b’></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00066-421f66c2-ef40-4695-a32c-48ec7065ed2f",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     527
    ],
    "deepnote_to_be_reexecuted": false,
    "execution": {
     "iopub.execute_input": "2020-08-14T19:33:41.167321Z",
     "iopub.status.busy": "2020-08-14T19:33:41.162766Z",
     "iopub.status.idle": "2020-08-14T19:33:41.185982Z",
     "shell.execute_reply": "2020-08-14T19:33:41.186894Z"
    },
    "execution_millis": 56,
    "execution_start": 1642208876670,
    "output_cleared": false,
    "papermill": {
     "duration": 0.241598,
     "end_time": "2020-08-14T19:33:41.187033",
     "exception": false,
     "start_time": "2020-08-14T19:33:40.945435",
     "status": "completed"
    },
    "source_hash": "efd8c704",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot data for all clusters\n",
    "obj_list = []\n",
    "\n",
    "all_clusters = list(set(cluster_id))\n",
    "for i_cluster, cluster in enumerate(all_clusters):\n",
    "\n",
    "    boolean = cluster_id == cluster\n",
    "\n",
    "    # create plotly object\n",
    "    plot_obj = go.Scatter3d(\n",
    "        x=T[boolean, 0],\n",
    "        y=T[boolean, 1],\n",
    "        z=T[boolean, 2],\n",
    "        text=list(FeatureDF.loc[boolean, \"Batch\"]),\n",
    "        hoverinfo=\"text\",\n",
    "        hovertemplate = 'Batch %{text:2.0}',\n",
    "        name=f\"Cluster {i_cluster+1}\",\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=7, opacity=0.75),\n",
    "    )\n",
    "\n",
    "    # append object to list\n",
    "    obj_list.append(plot_obj)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"<br>K-Cluster Scatterplot\",\n",
    "    title_x=0.5,\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=\"PC 1\"), yaxis=dict(title=\"PC 2\"), zaxis=dict(title=\"PC 3\")\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    margin=dict(l=0, r=0, b=0, t=0),\n",
    "    legend=dict(x=1.0, y=0.5),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=obj_list, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00067-201d1d13-7296-4f08-b6e6-097cf53c2227",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 59,
    "execution_start": 1642208876733,
    "output_cleared": true,
    "papermill": {
     "duration": 0.214656,
     "end_time": "2020-08-14T19:33:41.577597",
     "exception": false,
     "start_time": "2020-08-14T19:33:41.362941",
     "status": "completed"
    },
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=27d58a9b-9aaa-47c5-b041-7e32d6d185a5' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6e9fa5cf-cdce-4afb-a43a-364f5f29de40",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "papermill": {
   "duration": 150.464744,
   "end_time": "2020-08-14T19:33:42.280444",
   "environment_variables": {},
   "exception": null,
   "input_path": "../Learning_Modules/NB3_SOLUTION_Beer_PCA.ipynb",
   "output_path": "./Release/NB3_SOLUTION_Beer_PCA.ipynb",
   "parameters": {},
   "start_time": "2020-08-14T19:31:11.815700",
   "version": "2.1.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
